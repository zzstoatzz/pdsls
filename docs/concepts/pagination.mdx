---
title: "Pagination"
description: "why cursor-based pagination and the tradeoffs involved"
---

# pagination in atproto

## the pagination problem

when a collection contains thousands or millions of records, returning all results in a single response is impractical:
- network timeouts
- memory constraints
- poor user experience (long wait times)
- server resource exhaustion

pagination solves this by breaking large result sets into manageable pages.

## cursor-based vs offset-based

### offset-based pagination (traditional)
```
page 1: OFFSET 0 LIMIT 50
page 2: OFFSET 50 LIMIT 50
page 3: OFFSET 100 LIMIT 50
```

**advantages:**
- random access to any page
- intuitive mental model (page numbers)
- simple implementation

**disadvantages:**
- performance degrades with deep pagination (large offsets)
- inconsistent results when data changes (insertions/deletions shift pages)
- expensive for databases (must count/skip all preceding records)

### cursor-based pagination (atproto)
```
page 1: START
page 2: cursor=abc123
page 3: cursor=def456
```

**advantages:**
- consistent performance regardless of position
- stable results despite concurrent modifications
- server can optimize (index seeks, not scans)
- natural for append-only logs

**disadvantages:**
- no random access (can't jump to page 5)
- can't go backwards (usually)
- cursors are opaque (can't reason about position)

## why atproto chose cursors

atproto repositories are **append-only logs** with characteristics that favor cursor-based pagination:

### 1. temporal ordering
records have timestamp identifiers (tids) that create natural ordering. cursors can encode "start after this tid" efficiently.

### 2. distributed nature
atproto is federated - multiple pds instances, multiple repositories. offset pagination breaks down across distributed data sources. cursor pagination works naturally.

### 3. real-time updates
repositories are live, constantly updated. offset pagination creates inconsistencies:
- you fetch page 1
- someone creates 10 new records
- you fetch page 2 with `OFFSET 50`
- you miss 10 records or see duplicates

cursors are stable anchors: "start after record X" regardless of what's inserted before X.

### 4. performance at scale
deep offsets require scanning all preceding records. cursors use index seeks directly to the resume point.

## cursor opacity

cursors are **intentionally opaque** - they're implementation details, not part of the api contract.

### why opaque?

**implementation flexibility**: server can change cursor format without breaking clients:
- today: base64(rkey)
- tomorrow: base64(rkey + timestamp + hash)
- next week: encrypted token

**security**: prevents cursor manipulation:
- can't craft cursors to access restricted data
- can't reverse-engineer pagination logic
- server validates cursor authenticity

**optimization**: server can embed metadata:
- query continuation state
- cache keys
- pagination hints

### cursor lifetime

cursors are short-lived by design:
- typically valid for minutes to hours
- may expire if collection mutates significantly
- no guarantees about long-term validity

this is intentional - cursor-based pagination is for **streaming through current state**, not bookmarking positions for later.

## consistency guarantees

cursor-based pagination provides **read-your-writes consistency** within a session:
- once you receive a cursor, that position is stable
- subsequent requests with that cursor see consistent ordering
- but: you might miss records inserted during your pagination session

this is a **tradeoff**: consistency vs completeness. atproto chooses consistency (stable positions) over completeness (seeing every insert).

## forward-only traversal

most cursor implementations (including atproto) are **forward-only**:
- you can't go backwards
- you can't jump to arbitrary positions
- you must follow the chain: page 1 → 2 → 3

### why forward-only?

**simpler semantics**: "next page" is well-defined. "previous page" is ambiguous when data changes.

**better caching**: servers can cache "next cursor" but not "previous cursor" efficiently.

**matches use cases**: most pagination is forward (infinite scroll, data exports, processing pipelines).

## performance characteristics

### best case: sequential access
```
page 1: O(limit)           # fetch limit records
page 2: O(limit)           # seek to cursor, fetch limit records
page N: O(limit)           # constant time per page
```

regardless of N, each page fetch is O(limit) - the cursor points directly to the resume position.

### comparison to offset pagination
```
page 1: O(limit)           # fetch limit records
page 2: O(offset + limit)  # skip offset, fetch limit
page N: O(N*limit)         # skip N*limit records
```

offset pagination degrades linearly with page number.

### worst case: expired cursor
if cursor expires or collection changes dramatically:
```
page 1: O(limit)
page 2: cursor expired → restart from beginning
```

this is why cursors should be used immediately, not stored.

## implications for clients

### stateless pagination
each page request is independent - no server-side session state. the cursor encodes all necessary continuation information.

### no total count
cursor-based apis typically don't provide total record counts because:
- expensive to compute on large collections
- value changes during pagination anyway
- not needed for infinite scroll ux

### streaming model
cursor pagination encourages a **streaming** mental model:
- process records as they arrive
- don't try to load everything into memory
- think "pipeline" not "fetch all"

## when cursors aren't enough

cursor pagination has limitations for certain use cases:

### random access
can't jump to "page 5" or "middle of collection". if needed, use search/filtering with date ranges instead.

### progress indication
can't show "page 3 of 10". for progress, use approximations:
- "fetched N records so far"
- "processing since timestamp X"

### reverse chronological
atproto cursors are typically forward-only. for reverse ordering, the api must support `reverse` parameter (which pdsx exposes).

## atproto-specific details

### tid-based cursors
atproto records use timestamp identifiers (tids) as record keys. cursors often encode the last-seen tid:
```
cursor: "3lyqmkpiprs2w"
       └─ this is a tid (timestamp identifier)
```

### collection-scoped
cursors are specific to:
- repository (did)
- collection (nsid)
- query parameters

changing any parameter invalidates the cursor.

### no server-side state
atproto cursors are stateless - the server doesn't remember your pagination session. all state is in the cursor token itself.

## design philosophy

cursor-based pagination reflects atproto's design principles:

**1. scalability first**: optimize for billions of records, not billions of users accessing page 1.

**2. consistency over completeness**: stable ordering matters more than seeing every concurrent insert.

**3. streaming over batch**: encourage processing data as streams, not downloading entire collections.

**4. simple clients**: clients don't need complex pagination logic - just "follow the cursor."

## further reading

- [offset vs cursor pagination patterns](https://slack.engineering/evolving-api-pagination-at-slack/)
- [why cursor pagination](https://jsonapi.org/profiles/ethanresnick/cursor-pagination/)
- [atproto repository spec](https://atproto.com/specs/repository)
