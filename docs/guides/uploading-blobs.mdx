---
title: "Uploading Blobs"
description: "how to upload and use images, videos, and other binary content"
---

# how to upload blobs

this guide shows you how to upload binary content (images, videos, etc.) and use it in records.

## basic upload

### upload a single file

```bash
pdsx upload-blob photo.jpg
```

output:
```
âœ“ blob uploaded successfully

blob reference:
{
  "$type": "blob",
  "ref": {"$link": "bafkreif4oxjpqppiy6qvxpmgk7dv2sgxh6kanc5e5aztvgqvqho2q34c5u"},
  "mimeType": "image/jpeg",
  "size": 49004
}

use this blob reference in records (e.g., for post embeds)
```

### what you get back

- **$type**: always "blob"
- **ref.$link**: the cid (content identifier) - unique hash of your file
- **mimeType**: detected content type
- **size**: file size in bytes

## uploading multiple files

### upload several images

```bash
# upload images one by one
pdsx upload-blob image1.jpg > blob1.json
pdsx upload-blob image2.jpg > blob2.json
pdsx upload-blob image3.jpg > blob3.json
```

### batch upload script

```bash
#!/bin/bash

IMAGES_DIR="./photos"
OUTPUT_DIR="./blob_refs"

mkdir -p "$OUTPUT_DIR"

for img in "$IMAGES_DIR"/*.jpg; do
    filename=$(basename "$img")
    echo "uploading $filename..."

    pdsx upload-blob "$img" > "$OUTPUT_DIR/${filename%.jpg}.json"

    # be nice to the server
    sleep 0.5
done

echo "all images uploaded to $OUTPUT_DIR"
```

## using blob references

### in post embeds (manual construction)

the blob reference needs to be part of a properly structured embed. here's the structure:

```json
{
  "$type": "app.bsky.feed.post",
  "text": "check out this photo!",
  "embed": {
    "$type": "app.bsky.embed.images",
    "images": [
      {
        "$type": "app.bsky.embed.images#image",
        "image": {
          "$type": "blob",
          "ref": {"$link": "bafkreif4oxjpqppiy6qvxpmgk7dv2sgxh6kanc5e5aztvgqvqho2q34c5u"},
          "mimeType": "image/jpeg",
          "size": 49004
        },
        "alt": "a beautiful sunset",
        "aspectRatio": {
          "$type": "app.bsky.embed.defs#aspectRatio",
          "width": 1920,
          "height": 1080
        }
      }
    ]
  },
  "createdAt": "2025-11-08T00:00:00.000Z"
}
```

### programmatic usage (python)

```python
import subprocess
import json

def upload_blob(file_path: str) -> dict:
    """upload a blob and return the reference."""
    result = subprocess.run(
        ["pdsx", "upload-blob", file_path],
        capture_output=True,
        text=True
    )

    # parse json output
    output = result.stdout
    # extract json between "blob reference:" and end
    json_start = output.find("{")
    json_end = output.rfind("}") + 1
    blob_ref = json.loads(output[json_start:json_end])

    return blob_ref

# upload image
blob_ref = upload_blob("photo.jpg")
print(f"uploaded: {blob_ref['ref']['$link']}")

# use in record creation
# (you'd build the full embed structure here)
```

## handling different file types

### images

```bash
# jpeg
pdsx upload-blob photo.jpg

# png
pdsx upload-blob screenshot.png

# gif
pdsx upload-blob animation.gif

# webp
pdsx upload-blob modern.webp
```

### videos (if supported by pds)

```bash
pdsx upload-blob video.mp4
```

note: video support varies by pds instance and may have different size limits.

## compressing files before upload

### images

resize large images to stay under limits:

```bash
# using imagemagick
convert large.jpg -resize 1920x1920\> compressed.jpg
pdsx upload-blob compressed.jpg

# using ffmpeg
ffmpeg -i large.jpg -vf scale=1920:-1 compressed.jpg
pdsx upload-blob compressed.jpg
```

### videos

compress videos to reduce size:

```bash
# compress video with ffmpeg
ffmpeg -i input.mp4 -crf 28 -preset medium compressed.mp4
pdsx upload-blob compressed.mp4
```

## checking file size before upload

```bash
#!/bin/bash

FILE="photo.jpg"
MAX_SIZE=$((1024 * 1024))  # 1mb in bytes

SIZE=$(stat -f%z "$FILE" 2>/dev/null || stat -c%s "$FILE" 2>/dev/null)

if [ "$SIZE" -gt "$MAX_SIZE" ]; then
    echo "error: file too large ($SIZE bytes, max $MAX_SIZE)"
    echo "compress it first"
    exit 1
fi

pdsx upload-blob "$FILE"
```

## error handling

### file not found

```bash
pdsx upload-blob missing.jpg
# error: file not found: missing.jpg
```

**solution**: check file path
```bash
ls missing.jpg  # verify file exists
pdsx upload-blob /full/path/to/photo.jpg  # use absolute path
```

### not authenticated

```bash
pdsx upload-blob photo.jpg
# error: not authenticated
```

**solution**: set credentials
```bash
export ATPROTO_HANDLE=your.handle
export ATPROTO_PASSWORD=your-password
pdsx upload-blob photo.jpg
```

### file too large

```bash
pdsx upload-blob huge.jpg
# error: blob exceeds size limit
```

**solution**: compress the file (see above)

## blob lifecycle timing

blobs are temporary (1 hour) until referenced:

```bash
# upload blob
pdsx upload-blob photo.jpg
# blob ref: bafkreif...

# you have ~1 hour to use it in a record

# if you don't use it, it's garbage collected
```

**best practice**: upload, then immediately use in record

### workflow example

```bash
#!/bin/bash

# 1. upload blob
BLOB_JSON=$(pdsx upload-blob photo.jpg)

# 2. extract cid
CID=$(echo "$BLOB_JSON" | jq -r '.ref["$link"]')

# 3. immediately use in record creation
# (your application code here)
# create post with embed using $CID

echo "posted with image $CID"
```

## bulk upload with progress

```python
import subprocess
import json
from pathlib import Path
from typing import List, Dict

def upload_directory(
    dir_path: str,
    extensions: List[str] = [".jpg", ".png", ".gif"]
) -> List[Dict]:
    """upload all images in a directory."""
    path = Path(dir_path)
    files = []

    for ext in extensions:
        files.extend(path.glob(f"*{ext}"))

    uploaded = []
    total = len(files)

    for i, file in enumerate(files, 1):
        print(f"uploading {i}/{total}: {file.name}")

        result = subprocess.run(
            ["pdsx", "upload-blob", str(file)],
            capture_output=True,
            text=True
        )

        # parse blob ref
        output = result.stdout
        json_start = output.find("{")
        json_end = output.rfind("}") + 1
        blob_ref = json.loads(output[json_start:json_end])

        uploaded.append({
            "filename": file.name,
            "blob_ref": blob_ref
        })

    return uploaded

# usage
refs = upload_directory("./photos")
print(f"uploaded {len(refs)} images")

# save refs for later use
with open("uploaded_refs.json", "w") as f:
    json.dump(refs, f, indent=2)
```

## content addressing benefits

same file = same cid:

```bash
# upload photo
pdsx upload-blob cat.jpg
# cid: bafkreiabc123...

# upload same photo again
pdsx upload-blob cat.jpg
# cid: bafkreiabc123... (identical!)
```

**implication**: you can detect duplicates by comparing cids

```python
def is_duplicate(file_path: str, existing_cids: set) -> bool:
    """check if file was already uploaded."""
    result = subprocess.run(
        ["pdsx", "upload-blob", file_path],
        capture_output=True,
        text=True
    )

    output = result.stdout
    json_start = output.find("{")
    json_end = output.rfind("}") + 1
    blob_ref = json.loads(output[json_start:json_end])

    cid = blob_ref["ref"]["$link"]

    return cid in existing_cids
```

## mime type detection

pdsx (via atproto library) automatically detects mime types:

```bash
pdsx upload-blob photo.jpg
# mimeType: "image/jpeg"

pdsx upload-blob screenshot.png
# mimeType: "image/png"

pdsx upload-blob video.mp4
# mimeType: "video/mp4"
```

detection is based on:
- file magic bytes (content inspection)
- file extension
- server validation

## next steps

- understand [blob concepts](../concepts/blobs.mdx) - content addressing, cids, lifecycle
- see [quickstart](../quickstart.mdx) for basics
- learn about [records](../concepts/records.mdx) to understand how blobs fit in
